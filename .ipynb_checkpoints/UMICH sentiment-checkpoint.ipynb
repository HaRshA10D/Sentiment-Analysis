{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import urllib.request\n",
    "\n",
    "test_data_url = \"https://dl.dropboxusercontent.com/u/8082731/datasets/UMICH-SI650/testdata.txt\"\n",
    "train_data_url = \"https://dl.dropboxusercontent.com/u/8082731/datasets/UMICH-SI650/training.txt\"\n",
    "\n",
    "test_data_file_name = 'test_data.csv'\n",
    "train_data_file_name = 'train_data.csv'\n",
    "\n",
    "test_data_f = urllib.request.urlretrieve(test_data_url,test_data_file_name)\n",
    "train_data_f = urllib.request.urlretrieve(train_data_url,train_data_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data_df = pd.read_csv(test_data_file_name,header=None,delimiter=\"\\t\",quoting=3)\n",
    "test_data_df.columns = [\"Text\"]\n",
    "\n",
    "train_data_df = pd.read_csv(train_data_file_name,header=None,delimiter=\"\\t\",quoting=3)\n",
    "train_data_df.columns = [\"Sentiment\",\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7086, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33052, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this was the first clive cussler i've ever rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I liked the Da Vinci Code but it ultimatly did...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                               Text\n",
       "0          1            The Da Vinci Code book is just awesome.\n",
       "1          1  this was the first clive cussler i've ever rea...\n",
       "2          1                   i liked the Da Vinci Code a lot.\n",
       "3          1                   i liked the Da Vinci Code a lot.\n",
       "4          1  I liked the Da Vinci Code but it ultimatly did..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" I don't care what anyone says, I like Hillar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have an awesome time at purdue!..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yep, I'm still in London, which is pretty awes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have to say, I hate Paris Hilton's behavior bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i will love the lakers.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  \" I don't care what anyone says, I like Hillar...\n",
       "1                  have an awesome time at purdue!..\n",
       "2  Yep, I'm still in London, which is pretty awes...\n",
       "3  Have to say, I hate Paris Hilton's behavior bu...\n",
       "4                            i will love the lakers."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3995\n",
       "0    3091\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.886819079875812"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean([len(s.split(' ')) for s in train_data_df.Text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk,re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens,stemmer):\n",
    "    stemmed = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        stemmed.append(stemmer.stem(token))\n",
    "    \n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens,stemmer)\n",
    "    return stems\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word',tokenizer=tokenize,lowercase=True,stop_words='english',max_features=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_data_features = vectorizer.fit_transform(train_data_df.Text.tolist() + test_data_df.Text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40138, 85)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_data_features_nd = corpus_data_features.toarray()\n",
    "corpus_data_features_nd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaa',\n",
       " 'amaz',\n",
       " 'angelina',\n",
       " 'awesom',\n",
       " 'beauti',\n",
       " 'becaus',\n",
       " 'boston',\n",
       " 'brokeback',\n",
       " 'citi',\n",
       " 'code',\n",
       " 'cool',\n",
       " 'cruis',\n",
       " 'd',\n",
       " 'da',\n",
       " 'drive',\n",
       " 'francisco',\n",
       " 'friend',\n",
       " 'fuck',\n",
       " 'geico',\n",
       " 'good',\n",
       " 'got',\n",
       " 'great',\n",
       " 'ha',\n",
       " 'harri',\n",
       " 'harvard',\n",
       " 'hate',\n",
       " 'hi',\n",
       " 'hilton',\n",
       " 'honda',\n",
       " 'imposs',\n",
       " 'joli',\n",
       " 'just',\n",
       " 'know',\n",
       " 'laker',\n",
       " 'left',\n",
       " 'like',\n",
       " 'littl',\n",
       " 'london',\n",
       " 'look',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'm',\n",
       " 'macbook',\n",
       " 'make',\n",
       " 'miss',\n",
       " 'mission',\n",
       " 'mit',\n",
       " 'mountain',\n",
       " 'movi',\n",
       " 'need',\n",
       " 'new',\n",
       " 'oh',\n",
       " 'onli',\n",
       " 'pari',\n",
       " 'peopl',\n",
       " 'person',\n",
       " 'potter',\n",
       " 'purdu',\n",
       " 'realli',\n",
       " 'right',\n",
       " 'rock',\n",
       " 's',\n",
       " 'said',\n",
       " 'san',\n",
       " 'say',\n",
       " 'seattl',\n",
       " 'shanghai',\n",
       " 'stori',\n",
       " 'stupid',\n",
       " 'suck',\n",
       " 't',\n",
       " 'thi',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'time',\n",
       " 'tom',\n",
       " 'toyota',\n",
       " 'ucla',\n",
       " 've',\n",
       " 'vinci',\n",
       " 'wa',\n",
       " 'want',\n",
       " 'way',\n",
       " 'whi',\n",
       " 'work']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist = np.sum(corpus_data_features_nd,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1179 aaa\n",
      "485 amaz\n",
      "1765 angelina\n",
      "3170 awesom\n",
      "2146 beauti\n",
      "1694 becaus\n",
      "2190 boston\n",
      "2000 brokeback\n",
      "423 citi\n",
      "2003 code\n",
      "481 cool\n",
      "2031 cruis\n",
      "439 d\n",
      "2087 da\n",
      "433 drive\n",
      "1926 francisco\n",
      "477 friend\n",
      "452 fuck\n",
      "1085 geico\n",
      "773 good\n",
      "571 got\n",
      "1178 great\n",
      "776 ha\n",
      "2094 harri\n",
      "2103 harvard\n",
      "4492 hate\n",
      "794 hi\n",
      "2086 hilton\n",
      "2192 honda\n",
      "1098 imposs\n",
      "1764 joli\n",
      "1054 just\n",
      "896 know\n",
      "2019 laker\n",
      "425 left\n",
      "4080 like\n",
      "507 littl\n",
      "2233 london\n",
      "811 look\n",
      "421 lot\n",
      "10334 love\n",
      "1568 m\n",
      "1059 macbook\n",
      "631 make\n",
      "1098 miss\n",
      "1101 mission\n",
      "1340 mit\n",
      "2081 mountain\n",
      "1207 movi\n",
      "1220 need\n",
      "459 new\n",
      "551 oh\n",
      "674 onli\n",
      "2094 pari\n",
      "1018 peopl\n",
      "454 person\n",
      "2093 potter\n",
      "1167 purdu\n",
      "2126 realli\n",
      "661 right\n",
      "475 rock\n",
      "3914 s\n",
      "495 said\n",
      "2038 san\n",
      "627 say\n",
      "2019 seattl\n",
      "1189 shanghai\n",
      "467 stori\n",
      "2886 stupid\n",
      "4614 suck\n",
      "1455 t\n",
      "1705 thi\n",
      "662 thing\n",
      "1524 think\n",
      "781 time\n",
      "2117 tom\n",
      "2028 toyota\n",
      "2008 ucla\n",
      "774 ve\n",
      "2001 vinci\n",
      "3703 wa\n",
      "1656 want\n",
      "932 way\n",
      "547 whi\n",
      "512 work\n"
     ]
    }
   ],
   "source": [
    "for tag,count in zip(vocab,dist):\n",
    "    print(count,tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(corpus_data_features_nd[0:len(train_data_df)],train_data_df.Sentiment,train_size=0.85,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98       467\n",
      "          1       0.99      0.98      0.99       596\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(corpus_data_features_nd[0:len(train_data_df)],train_data_df.Sentiment)\n",
    "\n",
    "test_pred = log_model.predict(corpus_data_features_nd[len(train_data_df):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 I'd love a Toyota van..\n",
      "1 San Francisco was brilliant, Sausalito...\n",
      "0 State Farm sucks ass!\n",
      "0 i was so sick of being a cashier at citi trends and dealing with all of those stupid people.\n",
      "0 I hate Tom Cruise.\n",
      "1 I LOVE Seattle!!\n",
      "1 but the macbook looks so awesome.\n",
      "1 I think at this moment i love San Francisco better than L. A..\n",
      "1 we need at least ONE beautiful girl at ucla.\n",
      "1 I love paris hilton...\n",
      "0 & i adore my little honda < 3.\n",
      "0 And I hate those Geico commercials with the gecko.\n",
      "1 Love Story At Harvard [ awesome drama!\n",
      "1 I think at this moment i love San Francisco better than L. A..\n",
      "1 anyways i loved beijing as much as i loved shanghai.\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "spl = random.sample(range(len(test_pred)),15)\n",
    "\n",
    "for text,sentiment in zip(test_data_df.Text[spl],test_pred[spl]):\n",
    "    print(sentiment,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
